{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeReviewDetection(CNN_LSTM_Doc2Vec_TFIDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ0ixwyPi4wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import TimeDistributed, GlobalAveragePooling1D, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dropout, Flatten, Bidirectional, Dense, Activation, TimeDistributed\n",
        "from keras.models import Model, Sequential\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from string import ascii_lowercase\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models import doc2vec\n",
        "from gensim.models import KeyedVectors\n",
        "import itertools, nltk, snowballstemmer, re\n",
        "\n",
        "LabeledSentence = doc2vec.LabeledSentence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI3gf6YzoFJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LabeledLineSentence(object):\n",
        "    def __init__(self, sources):\n",
        "        self.sources = sources\n",
        "        \n",
        "        flipped = {}\n",
        "        \n",
        "        # make sure that keys are unique\n",
        "        for key, value in sources.items():\n",
        "            if value not in flipped:\n",
        "                flipped[value] = [key]\n",
        "            else:\n",
        "                raise Exception('Non-unique prefix encountered')\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for source, prefix in self.sources.items():\n",
        "            with utils.smart_open(source) as fin:\n",
        "                for item_no, line in enumerate(fin):\n",
        "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
        "    \n",
        "    def to_array(self):\n",
        "        self.sentences = []\n",
        "        for source, prefix in self.sources.items():\n",
        "            with utils.smart_open(source) as fin:\n",
        "                for item_no, line in enumerate(fin):\n",
        "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
        "        return self.sentences\n",
        "    \n",
        "    def sentences_perm(self):\n",
        "        shuffled = list(self.sentences)\n",
        "        random.shuffle(shuffled)\n",
        "        return shuffled"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PICtWlaoOEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/deceptive-opinion.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_xhGol6ocPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['polarity'] = np.where(data['polarity']=='positive', 1, 0)\n",
        "data['deceptive'] = np.where(data['deceptive']=='truthful', 1, 0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhmnlGSVoim0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ffbb40aa-64e1-4cd4-d5aa-0568ab556876"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deceptive</th>\n",
              "      <th>hotel</th>\n",
              "      <th>polarity</th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>conrad</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>We stayed for a one night getaway with family ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>Triple A rate with upgrade to view room was le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>This comes a little late as I'm finally catchi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>omni</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>I asked for a high floor away from the elevato...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   deceptive  ...                                               text\n",
              "0          1  ...  We stayed for a one night getaway with family ...\n",
              "1          1  ...  Triple A rate with upgrade to view room was le...\n",
              "2          1  ...  This comes a little late as I'm finally catchi...\n",
              "3          1  ...  The Omni Chicago really delivers on all fronts...\n",
              "4          1  ...  I asked for a high floor away from the elevato...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4sugIwrpDIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = data.sample(frac=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b98OQ-XKpTRh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1d09aee4-d39f-4f58-c273-070e12f4124a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deceptive</th>\n",
              "      <th>hotel</th>\n",
              "      <th>polarity</th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>674</th>\n",
              "      <td>0</td>\n",
              "      <td>monaco</td>\n",
              "      <td>1</td>\n",
              "      <td>MTurk</td>\n",
              "      <td>Upon entering the Hotel Monaco CHicago, i coul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1281</th>\n",
              "      <td>0</td>\n",
              "      <td>sheraton</td>\n",
              "      <td>0</td>\n",
              "      <td>MTurk</td>\n",
              "      <td>For the price, you would think this would be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>1</td>\n",
              "      <td>omni</td>\n",
              "      <td>0</td>\n",
              "      <td>Web</td>\n",
              "      <td>My family booked five nitghts at the Omni Chic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1389</th>\n",
              "      <td>0</td>\n",
              "      <td>affinia</td>\n",
              "      <td>0</td>\n",
              "      <td>MTurk</td>\n",
              "      <td>I recently stayed at the Affinia Hotel in Chic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296</th>\n",
              "      <td>0</td>\n",
              "      <td>knickerbocker</td>\n",
              "      <td>0</td>\n",
              "      <td>MTurk</td>\n",
              "      <td>While the hotel certainly seems to look beauti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      deceptive  ...                                               text\n",
              "674           0  ...  Upon entering the Hotel Monaco CHicago, i coul...\n",
              "1281          0  ...  For the price, you would think this would be a...\n",
              "833           1  ...  My family booked five nitghts at the Omni Chic...\n",
              "1389          0  ...  I recently stayed at the Affinia Hotel in Chic...\n",
              "1296          0  ...  While the hotel certainly seems to look beauti...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLd9VnUKpWac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "136451b1-8ab3-49e6-f3fb-9a40679e5621"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deceptive</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1600.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500156</td>\n",
              "      <td>0.500156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         deceptive     polarity\n",
              "count  1600.000000  1600.000000\n",
              "mean      0.500000     0.500000\n",
              "std       0.500156     0.500156\n",
              "min       0.000000     0.000000\n",
              "25%       0.000000     0.000000\n",
              "50%       0.500000     0.500000\n",
              "75%       1.000000     1.000000\n",
              "max       1.000000     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT0o5lq6pfbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_class(c):\n",
        "    if c['polarity'] == 1 and c['deceptive'] == 1:\n",
        "        return [1,1]\n",
        "    elif c['polarity'] == 1 and c['deceptive'] == 0:\n",
        "        return [1,0]\n",
        "    elif c['polarity'] == 0 and c['deceptive'] == 1:\n",
        "        return [0,1]\n",
        "    else:\n",
        "        return [0,0]\n",
        "    \n",
        "def specific_class(c):\n",
        "    if c['polarity'] == 1 and c['deceptive'] == 1:\n",
        "        return \"TRUE_POSITIVE\"\n",
        "    elif c['polarity'] == 1 and c['deceptive'] == 0:\n",
        "        return \"FALSE_POSITIVE\"\n",
        "    elif c['polarity'] == 0 and c['deceptive'] == 1:\n",
        "        return \"TRUE_NEGATIVE\"\n",
        "    else:\n",
        "        return \"FALSE_NEGATIVE\"\n",
        "\n",
        "data['final_class'] = data.apply(create_class, axis=1)\n",
        "data['given_class'] = data.apply(specific_class, axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FPoOyMCp1ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ac84b0cc-6e20-4504-b457-6b2ad2165182"
      },
      "source": [
        "data['final_class']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [1, 1]\n",
              "1       [1, 1]\n",
              "2       [1, 1]\n",
              "3       [1, 1]\n",
              "4       [1, 1]\n",
              "         ...  \n",
              "1595    [0, 0]\n",
              "1596    [0, 0]\n",
              "1597    [0, 0]\n",
              "1598    [0, 0]\n",
              "1599    [0, 0]\n",
              "Name: final_class, Length: 1600, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qiw8jyZgqGDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d6cfdcd8-e61e-4233-e892-a307eb9f32ec"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deceptive</th>\n",
              "      <th>hotel</th>\n",
              "      <th>polarity</th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>final_class</th>\n",
              "      <th>given_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>conrad</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>We stayed for a one night getaway with family ...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>TRUE_POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>Triple A rate with upgrade to view room was le...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>TRUE_POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>This comes a little late as I'm finally catchi...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>TRUE_POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>omni</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>TRUE_POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>I asked for a high floor away from the elevato...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>TRUE_POSITIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   deceptive   hotel  ...  final_class    given_class\n",
              "0          1  conrad  ...       [1, 1]  TRUE_POSITIVE\n",
              "1          1   hyatt  ...       [1, 1]  TRUE_POSITIVE\n",
              "2          1   hyatt  ...       [1, 1]  TRUE_POSITIVE\n",
              "3          1    omni  ...       [1, 1]  TRUE_POSITIVE\n",
              "4          1   hyatt  ...       [1, 1]  TRUE_POSITIVE\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk7QwbHfqKbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import preprocessing \n",
        "   \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "\n",
        "data['given_class']= label_encoder.fit_transform(data['given_class'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORBLC6QZqXZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24d01831-e9ec-4a6c-9dd0-314fc190fc80"
      },
      "source": [
        "data['given_class'].unique()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHlaiRGvqcFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = data['given_class']\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QmGJ8A6qmui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "45663735-ff11-4b25-fedb-b298ab70c465"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>deceptive</th>\n",
              "      <th>hotel</th>\n",
              "      <th>polarity</th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>final_class</th>\n",
              "      <th>given_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>conrad</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>We stayed for a one night getaway with family ...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>Triple A rate with upgrade to view room was le...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>This comes a little late as I'm finally catchi...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>omni</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>hyatt</td>\n",
              "      <td>1</td>\n",
              "      <td>TripAdvisor</td>\n",
              "      <td>I asked for a high floor away from the elevato...</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   deceptive   hotel  ...  final_class given_class\n",
              "0          1  conrad  ...       [1, 1]           3\n",
              "1          1   hyatt  ...       [1, 1]           3\n",
              "2          1   hyatt  ...       [1, 1]           3\n",
              "3          1    omni  ...       [1, 1]           3\n",
              "4          1   hyatt  ...       [1, 1]           3\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQe5DQRwqrH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textData = pd.DataFrame(list(data['text']))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFTBnWJlqxo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5a85fca0-f35f-4a4b-d219-15af1af303b8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luPcCfUPr-tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "stemmer = snowballstemmer.EnglishStemmer()\n",
        "\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "stop.extend(['may','also','zero','one','two','three','four','five','six','seven','eight','nine','ten','across','among','beside','however','yet','within']+list(ascii_lowercase))\n",
        "stoplist = stemmer.stemWords(stop)\n",
        "stoplist = set(stoplist)\n",
        "stop = set(sorted(stop + list(stoplist)))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3dz2oUDssqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textData[0].replace('[!\"#%\\'()*+,-./:;<=>?@\\[\\]^_`{|}~1234567890’”“′‘\\\\\\]',' ',inplace=True,regex=True)\n",
        "wordlist = filter(None, \" \".join(list(set(list(itertools.chain(*textData[0].str.split(' ')))))).split(\" \"))\n",
        "data['stemmed_text_data'] = [' '.join(filter(None,filter(lambda word: word not in stop, line))) for line in textData[0].str.lower().str.split(' ')]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P489dayZs52m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "minimum_count = 1\n",
        "str_frequencies = pd.DataFrame(list(Counter(filter(None,list(itertools.chain(*data['stemmed_text_data'].str.split(' '))))).items()),columns=['word','count'])\n",
        "low_frequency_words = set(str_frequencies[str_frequencies['count'] < minimum_count]['word'])\n",
        "data['stemmed_text_data'] = [' '.join(filter(None,filter(lambda word: word not in low_frequency_words, line))) for line in data['stemmed_text_data'].str.split(' ')]\n",
        "data['stemmed_text_data'] = [\" \".join(stemmer.stemWords(re.sub('[!\"#%\\'()*+,-./:;<=>?@\\[\\]^_`{|}~1234567890’”“′‘\\\\\\]',' ', next_text).split(' '))) for next_text in data['stemmed_text_data']]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-zZ3onZtaqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lmtzr = WordNetLemmatizer()\n",
        "w = re.compile(\"\\w+\",re.I)\n",
        "\n",
        "def label_sentences(df, input_point):\n",
        "    labeled_sentences = []\n",
        "    list_sen = []\n",
        "    for index, datapoint in df.iterrows():\n",
        "        tokenized_words = re.findall(w,datapoint[input_point].lower())\n",
        "        labeled_sentences.append(LabeledSentence(words=tokenized_words, tags=['SENT_%s' %index]))\n",
        "        list_sen.append(tokenized_words)\n",
        "    return labeled_sentences, list_sen\n",
        "\n",
        "def train_doc2vec_model(labeled_sentences):\n",
        "    model = Doc2Vec(min_count=1, window=9, size=512, sample=1e-4, negative=5, workers=7)\n",
        "    model.build_vocab(labeled_sentences)\n",
        "    pretrained_weights = model.wv.syn0\n",
        "    vocab_size, embedding_size = pretrained_weights.shape\n",
        "    model.train(labeled_sentences, total_examples=vocab_size, epochs=400)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxO6rY7ythRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5ba4715f-fa3b-40d3-9f78-c1d6bbbed391"
      },
      "source": [
        "textData = data['stemmed_text_data'].to_frame().reset_index()\n",
        "sen, corpus = label_sentences(textData, 'stemmed_text_data')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtefl9hktnP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "71fd189a-ffa2-421d-d739-040e124aa588"
      },
      "source": [
        "doc2vec_model = train_doc2vec_model(sen)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGI6nc9GttOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0cfb0c48-5ce2-4464-f12c-5056654d6a02"
      },
      "source": [
        "doc2vec_model.save(\"doc2vec_model_opinion_corpus.d2v\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkMV-OXmubZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0c547ee0-9f2f-4b06-f8c8-fdc01c023576"
      },
      "source": [
        "doc2vec_model = Doc2Vec.load(\"doc2vec_model_opinion_corpus.d2v\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLxIt7AtugGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "tfidf1 = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False, ngram_range=(1,1))\n",
        "result_train1 = tfidf1.fit_transform(corpus)\n",
        "\n",
        "tfidf2 = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False, ngram_range=(1,2))\n",
        "result_train2 = tfidf2.fit_transform(corpus)\n",
        "\n",
        "tfidf3 = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False, ngram_range=(1,3))\n",
        "result_train3 = tfidf3.fit_transform(corpus)\n",
        "\n",
        "svd = TruncatedSVD(n_components=512, n_iter=40, random_state=34)\n",
        "tfidf_data1 = svd.fit_transform(result_train1)\n",
        "tfidf_data2 = svd.fit_transform(result_train2)\n",
        "tfidf_data3 = svd.fit_transform(result_train3)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsSyd9GWul9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "temp_textData = pd.DataFrame(list(data['text']))\n",
        "\n",
        "overall_pos_tags_tokens = []\n",
        "overall_pos = []\n",
        "overall_tokens = []\n",
        "overall_dep = []\n",
        "\n",
        "for i in range(1600):\n",
        "    doc = nlp(temp_textData[0][i])\n",
        "    given_pos_tags_tokens = []\n",
        "    given_pos = []\n",
        "    given_tokens = []\n",
        "    given_dep = []\n",
        "    for token in doc:\n",
        "        output = \"%s_%s\" % (token.pos_, token.tag_)\n",
        "        given_pos_tags_tokens.append(output)\n",
        "        given_pos.append(token.pos_)\n",
        "        given_tokens.append(token.tag_)\n",
        "        given_dep.append(token.dep_)\n",
        "        \n",
        "    overall_pos_tags_tokens.append(given_pos_tags_tokens)\n",
        "    overall_pos.append(given_pos)\n",
        "    overall_tokens.append(given_tokens)\n",
        "    overall_dep.append(given_dep)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLTBv3wjv8t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "count = CountVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
        "pos_tags_data = count.fit_transform(overall_pos_tags_tokens).todense()\n",
        "pos_data = count.fit_transform(overall_pos).todense()\n",
        "tokens_data = count.fit_transform(overall_tokens).todense()\n",
        "dep_data = count.fit_transform(overall_dep).todense()\n",
        "min_max_scaler = MinMaxScaler()\n",
        "normalized_pos_tags_data = min_max_scaler.fit_transform(pos_tags_data)\n",
        "normalized_pos_data = min_max_scaler.fit_transform(pos_data)\n",
        "normalized_tokens_data = min_max_scaler.fit_transform(tokens_data)\n",
        "normalized_dep_data = min_max_scaler.fit_transform(dep_data)\n",
        "\n",
        "final_pos_tags_data = np.zeros(shape=(1600, 512)).astype(np.float32)\n",
        "final_pos_data = np.zeros(shape=(1600, 512)).astype(np.float32)\n",
        "final_tokens_data = np.zeros(shape=(1600, 512)).astype(np.float32)\n",
        "final_dep_data = np.zeros(shape=(1600, 512)).astype(np.float32)\n",
        "final_pos_tags_data[:normalized_pos_tags_data.shape[0],:normalized_pos_tags_data.shape[1]] = normalized_pos_tags_data\n",
        "final_pos_data[:normalized_pos_data.shape[0],:normalized_pos_data.shape[1]] = normalized_pos_data\n",
        "final_tokens_data[:normalized_tokens_data.shape[0],:normalized_tokens_data.shape[1]] = normalized_tokens_data\n",
        "final_dep_data[:normalized_dep_data.shape[0],:normalized_dep_data.shape[1]] = normalized_dep_data"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBctJ2pKwXuS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1f688da8-8604-4ec1-ad74-6802495823a5"
      },
      "source": [
        "maxlength = []\n",
        "for i in range(0,len(sen)):\n",
        "    maxlength.append(len(sen[i][0]))\n",
        "    \n",
        "print(max(maxlength))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8DdppJQwchv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "68de4d86-a73c-48fc-f394-70718d77c609"
      },
      "source": [
        "def vectorize_comments(df,d2v_model):\n",
        "    y = []\n",
        "    comments = []\n",
        "    for i in range(0,df.shape[0]):\n",
        "        label = 'SENT_%s' %i\n",
        "        comments.append(d2v_model.docvecs[label])\n",
        "    df['vectorized_comments'] = comments\n",
        "    \n",
        "    return df\n",
        "\n",
        "textData = vectorize_comments(textData,doc2vec_model)\n",
        "print (textData.head(2))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   index  ...                                vectorized_comments\n",
            "0      0  ...  [-0.8686014, -0.8710503, -0.054903124, 1.67881...\n",
            "1      1  ...  [-0.39496598, 0.10856623, -0.30414745, 0.25194...\n",
            "\n",
            "[2 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFnJmltjwgu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate,GridSearchCV \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(textData[\"vectorized_comments\"].T.tolist(), \n",
        "                                                                     dummy_y, \n",
        "                                                                     test_size=0.1, \n",
        "                                                                     random_state=56)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTEioEN8wxV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(textData[\"vectorized_comments\"].T.tolist()).reshape((1,1600,512))\n",
        "y = np.array(dummy_y).reshape((1600,4))\n",
        "X_train2 = np.array(X_train).reshape((1,1440,512))\n",
        "y_train2 = np.array(y_train).reshape((1,1440,4))\n",
        "X_test2 = np.array(X_test).reshape((1,160,512))\n",
        "y_test2 = np.array(y_test).reshape((1,160,4))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTsWNTuCw05q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "Xtemp = textData[\"vectorized_comments\"].T.tolist()\n",
        "ytemp = data['given_class']\n",
        "training_indices = []\n",
        "testing_indices = []\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "skf.get_n_splits(Xtemp, ytemp)\n",
        "\n",
        "for train_index, test_index in skf.split(Xtemp, ytemp):\n",
        "    training_indices.append(train_index)\n",
        "    testing_indices.append(test_index)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LogXXJg4w7ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractTrainingAndTestingData(givenIndex):\n",
        "    X_train3 = np.zeros(shape=(1440, max(maxlength)+10, 512)).astype(np.float32)\n",
        "    Y_train3 = np.zeros(shape=(1440, 4)).astype(np.float32)\n",
        "    X_test3 = np.zeros(shape=(160, max(maxlength)+10, 512)).astype(np.float32)\n",
        "    Y_test3 = np.zeros(shape=(160, 4)).astype(np.float32)\n",
        "\n",
        "    empty_word = np.zeros(512).astype(np.float32)\n",
        "\n",
        "    count_i = 0\n",
        "    for i in training_indices[givenIndex]:\n",
        "        len1 = len(sen[i][0])\n",
        "        average_vector1 = np.zeros(512).astype(np.float32)\n",
        "        average_vector2 = np.zeros(512).astype(np.float32)\n",
        "        average_vector3 = np.zeros(512).astype(np.float32)\n",
        "        for j in range(max(maxlength)+10):\n",
        "            if j < len1:\n",
        "                X_train3[count_i,j,:] = doc2vec_model[sen[i][0][j]]\n",
        "                average_vector1 += result_train1[i, tfidf1.vocabulary_[sen[i][0][j]]] * doc2vec_model[sen[i][0][j]]\n",
        "                average_vector2 += result_train2[i, tfidf2.vocabulary_[sen[i][0][j]]] * doc2vec_model[sen[i][0][j]]\n",
        "                average_vector3 += result_train3[i, tfidf3.vocabulary_[sen[i][0][j]]] * doc2vec_model[sen[i][0][j]]\n",
        "            #elif j >= len1 and j < len1 + 379:\n",
        "            #    X_train3[count_i,j,:] = glove_data[i, j-len1, :]\n",
        "            elif j == len1:\n",
        "                X_train3[count_i,j,:] = tfidf_data1[i]\n",
        "            elif j == len1 + 1:\n",
        "                X_train3[count_i,j,:] = tfidf_data2[i]\n",
        "            elif j == len1+2:\n",
        "                X_train3[count_i,j,:] = tfidf_data3[i]\n",
        "            elif j == len1+3:\n",
        "                X_train3[count_i,j,:] = average_vector1\n",
        "            elif j == len1+4:\n",
        "                X_train3[count_i,j,:] = average_vector2\n",
        "            elif j == len1+5:\n",
        "                X_train3[count_i,j,:] = average_vector3\n",
        "            elif j == len1+6:\n",
        "                X_train3[count_i,j,:] = final_pos_tags_data[i] \n",
        "            elif j == len1+7:\n",
        "                X_train3[count_i,j,:] = final_pos_data[i]\n",
        "            elif j == len1+8:\n",
        "                X_train3[count_i,j,:] = final_tokens_data[i]\n",
        "            elif j == len1+9:\n",
        "                X_train3[count_i,j,:] = final_dep_data[i]\n",
        "            else:\n",
        "                X_train3[count_i,j,:] = empty_word\n",
        "\n",
        "        Y_train3[count_i,:] = dummy_y[i]\n",
        "        count_i += 1\n",
        "\n",
        "\n",
        "    count_i = 0\n",
        "    for i in testing_indices[givenIndex]:\n",
        "        len1 = len(sen[i][0])\n",
        "        average_vector1 = np.zeros(512).astype(np.float32)\n",
        "        average_vector2 = np.zeros(512).astype(np.float32)\n",
        "        average_vector3 = np.zeros(512).astype(np.float32)\n",
        "        for j in range(max(maxlength)+10):\n",
        "            if j < len1:\n",
        "                X_test3[count_i,j,:] = doc2vec_model[sen[i][0][j]]\n",
        "                average_vector1 += result_train1[i, tfidf1.vocabulary_[sen[i][0][j]]] * doc2vec_model[sen[i][0][j]]\n",
        "                average_vector2 += result_train2[i, tfidf2.vocabulary_[sen[i][0][j]]] * doc2vec_model[sen[i][0][j]]  \n",
        "                average_vector3 += result_train3[i, tfidf3.vocabulary_[sen[i][0][j]]] * doc2vec_model[sen[i][0][j]]\n",
        "            #elif j >= len1 and j < len1 + 379:\n",
        "            #    X_test3[count_i,j,:] = glove_data[i, j-len1, :]\n",
        "            elif j == len1:\n",
        "                X_test3[count_i,j,:] = tfidf_data1[i]\n",
        "            elif j == len1 + 1:\n",
        "                X_test3[count_i,j,:] = tfidf_data2[i]\n",
        "            elif j == len1+2:\n",
        "                X_test3[count_i,j,:] = tfidf_data3[i]\n",
        "            elif j == len1+3:\n",
        "                X_test3[count_i,j,:] = average_vector1\n",
        "            elif j == len1+4:\n",
        "                X_test3[count_i,j,:] = average_vector2\n",
        "            elif j == len1+5:\n",
        "                X_test3[count_i,j,:] = average_vector3\n",
        "            elif j == len1+6:\n",
        "                X_test3[count_i,j,:] = final_pos_tags_data[i]\n",
        "            elif j == len1+7:\n",
        "                X_test3[count_i,j,:] = final_pos_data[i]\n",
        "            elif j == len1+8:\n",
        "                X_test3[count_i,j,:] = final_tokens_data[i]\n",
        "            elif j == len1+9:\n",
        "                X_test3[count_i,j,:] = final_dep_data[i]\n",
        "            else:\n",
        "                X_test3[count_i,j,:] = empty_word\n",
        "\n",
        "        Y_test3[count_i,:] = dummy_y[i]\n",
        "        count_i += 1\n",
        "        \n",
        "    return X_train3, X_test3, Y_train3, Y_test3"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E6zyuahxLBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "b69aad6a-9c78-4d48-b70d-a8e5afb457db"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=128, kernel_size=9, padding='same', activation='relu', input_shape=(max(maxlength)+10,512)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv1D(filters=128, kernel_size=7, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.25, recurrent_dropout=0.2)))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 380, 128)          589952    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 380, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 190, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 190, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 190, 128)          114816    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 190, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 95, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 95, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 95, 128)           82048     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 95, 128)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100)               71600     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 404       \n",
            "=================================================================\n",
            "Total params: 858,820\n",
            "Trainable params: 858,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvMSBc50xZm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "\n",
        "final_accuracies = []\n",
        "    \n",
        "filename = 'weights.best.from_scratch%s.hdf5' % 9\n",
        "checkpointer = ModelCheckpoint(filepath=filename, verbose=1, save_best_only=True)\n",
        "X_train3, X_test3, Y_train3, Y_test3 = extractTrainingAndTestingData(9)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ZoiNCWxg02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdc065ca-c81e-46f9-b489-4ad2f4c2a4c1"
      },
      "source": [
        "history = model.fit(X_train3, Y_train3, epochs=15, batch_size=512, callbacks=[checkpointer], validation_data=(X_test3, Y_test3), verbose=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1440 samples, validate on 160 samples\n",
            "Epoch 1/15\n",
            "1440/1440 [==============================] - 41s 28ms/step - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.53444, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 2/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.5295 - accuracy: 0.7500 - val_loss: 0.4590 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.53444 to 0.45900, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 3/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.4538 - accuracy: 0.7566 - val_loss: 0.3945 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.45900 to 0.39446, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 4/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.3890 - accuracy: 0.8113 - val_loss: 0.3289 - val_accuracy: 0.8609\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.39446 to 0.32893, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 5/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.3334 - accuracy: 0.8571 - val_loss: 0.2848 - val_accuracy: 0.8734\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.32893 to 0.28479, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 6/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.2911 - accuracy: 0.8842 - val_loss: 0.2546 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.28479 to 0.25463, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 7/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.2544 - accuracy: 0.8983 - val_loss: 0.2477 - val_accuracy: 0.8844\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.25463 to 0.24770, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 8/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.2304 - accuracy: 0.9102 - val_loss: 0.2314 - val_accuracy: 0.8953\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.24770 to 0.23136, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 9/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.2060 - accuracy: 0.9210 - val_loss: 0.2247 - val_accuracy: 0.9062\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.23136 to 0.22468, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 10/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.1935 - accuracy: 0.9292 - val_loss: 0.2390 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.22468\n",
            "Epoch 11/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.1768 - accuracy: 0.9321 - val_loss: 0.2616 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.22468\n",
            "Epoch 12/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.1668 - accuracy: 0.9413 - val_loss: 0.2317 - val_accuracy: 0.9062\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.22468\n",
            "Epoch 13/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.1640 - accuracy: 0.9342 - val_loss: 0.2804 - val_accuracy: 0.8766\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.22468\n",
            "Epoch 14/15\n",
            "1440/1440 [==============================] - 41s 28ms/step - loss: 0.1385 - accuracy: 0.9516 - val_loss: 0.2227 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.22468 to 0.22266, saving model to weights.best.from_scratch9.hdf5\n",
            "Epoch 15/15\n",
            "1440/1440 [==============================] - 39s 27ms/step - loss: 0.1164 - accuracy: 0.9630 - val_loss: 0.2426 - val_accuracy: 0.8938\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.22266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5bX2zhjz_PR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f1c21f0d-ff3a-461d-8dfb-1d77bed6b839"
      },
      "source": [
        "model.evaluate(X_test3, Y_test3)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 2s 10ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24257557988166809, 0.893750011920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xuV5sSB0TRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}